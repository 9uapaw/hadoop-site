<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on Apache Hadoop Submarine</title>
    <link>/submarine/docs/</link>
    <description>Recent content in Docs on Apache Hadoop Submarine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Apache Software Foundation</copyright>
    
	<atom:link href="/submarine/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/BuildFromCode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/BuildFromCode/</guid>
      <description>Build Submarine From Source Code  Run &amp;lsquo;mvn install -DskipTests&amp;rsquo; from Hadoop source top level once.
 Navigate to hadoop-submarine folder and run &amp;lsquo;mvn clean package&amp;rsquo;.
 By default, hadoop-submarine is built based on hadoop 3.1.2 dependencies. Both yarn service runtime and tony runtime are built. You can also add a parameter of &amp;ldquo;-Phadoop-3.2&amp;rdquo; to specify the dependencies to hadoop 3.2.0.
 Hadoop-submarine can support hadoop 2.9.2 and hadoop 2.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/Examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/Examples/</guid>
      <description>Examples Here&amp;rsquo;re some examples about Submarine usage.
Running Distributed CIFAR 10 Tensorflow Job
Running Standalone CIFAR 10 PyTorch Job</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/HowToInstall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/HowToInstall/</guid>
      <description>How to Install Dependencies Submarine project may uses YARN Service (When Submarine YARN service runtime is being used, see QuickStart), Docker container, and GPU (when GPU hardware available and properly configured).
That means as an admin, you may have to properly setup YARN Service related dependencies, including: - YARN Registry DNS
Docker related dependencies, including: - Docker binary with expected versions. - Docker network which allows Docker container can talk to each other across different nodes.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/Index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/Index/</guid>
      <description>Submarine is a project which allows infra engineer / data scientist to run unmodified Tensorflow or PyTorch programs on YARN or Kubernetes.
Goals of Submarine:
 It allows jobs for easy access to data/models in HDFS and other storages.
 Can launch services to serve Tensorflow/MXNet models.
 Support run distributed Tensorflow jobs with simple configs.
 Support run standalone PyTorch jobs with simple configs.
 Support run user-specified Docker images.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/InstallationGuide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/InstallationGuide/</guid>
      <description>Submarine Installation Guide Prerequisites (Please note that all following prerequisites are just an example for you to install. You can always choose to install your own version of kernel, different users, different drivers, etc.).
Operating System The operating system and kernel versions we have tested are as shown in the following table, which is the recommneded minimum required versions.
   Enviroment Verion     Operating System centos-release-7-5.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/InstallationGuideChineseVersion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/InstallationGuideChineseVersion/</guid>
      <description>Submarine 安装说明 Prerequisites 操作系统 我们使用的操作系统版本是 centos-release-7-5.1804.el7.centos.x86_64, 内核版本是 3.10.0-862.el7.x86_64。
   Enviroment Verion     Operating System centos-release-7-5.1804.el7.centos.x86_64   Kernal 3.10.0-862.el7.x86_64    User &amp;amp; Group 如果操作系统中没有这些用户组和用户，必须添加。一部分用户是 hadoop 运行需要，一部分用户是 docker 运行需要。
adduser hdfs adduser mapred adduser yarn addgroup hadoop usermod -aG hdfs,hadoop hdfs usermod -aG mapred,hadoop mapred usermod -aG yarn,hadoop yarn usermod -aG hdfs,hadoop hadoop groupadd docker usermod -aG docker yarn usermod -aG docker hadoop  GCC 版本 gcc --version gcc (GCC) 4.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/QuickStart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/QuickStart/</guid>
      <description>Submarine Quick Start Guide Prerequisite Must:
 Apache Hadoop version newer than 2.7.3  Optional:
 Enable YARN Service Enable GPU on YARN Enable Docker on YARN Build Docker images  
Submarine Configuration After submarine 0.2.0, it supports two runtimes which are YARN service runtime and Linkedin&amp;rsquo;s TonY runtime for YARN. Each runtime can support both Tensorflow and PyTorch framework. But we don&amp;rsquo;t need to worry about the usage because the two runtime implements the same interface.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/RunningDistributedCifar10TFJobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/RunningDistributedCifar10TFJobs/</guid>
      <description>Cifar10 Tensorflow Estimator Example With YARN Service Prepare data for training CIFAR-10 is a common benchmark in machine learning for image recognition. Below example is based on CIFAR-10 dataset.
1) Checkout https://github.com/tensorflow/models/:
git clone https://github.com/tensorflow/models/  2) Go to models/tutorials/image/cifar10_estimator
3) Generate data by using following command: (required Tensorflow installed)
python generate_cifar10_tfrecords.py --data-dir=cifar-10-data  4) Upload data to HDFS
hadoop fs -put cifar-10-data/ /dataset/cifar-10-data  Warning:
Please note that YARN service doesn&amp;rsquo;t allow multiple services with the same name, so please run following command</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/RunningSingleNodeCifar10PTJobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/RunningSingleNodeCifar10PTJobs/</guid>
      <description>Tutorial: Running a standalone Cifar10 PyTorch Estimator Example. Currently, PyTorch integration with Submarine only supports PyTorch in standalone (non-distributed mode). Please also note that HDFS as a data source is not yet supported by PyTorch.
What is CIFAR-10? CIFAR-10 is a common benchmark in machine learning for image recognition. Below example is based on CIFAR-10 dataset.
Warning:
Please note that YARN service doesn&amp;rsquo;t allow multiple services with the same name, so please run following command</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/TestAndTroubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/TestAndTroubleshooting/</guid>
      <description>Test with a tensorflow job Distributed-shell + GPU + cgroup
... \ job run \ --env DOCKER_JAVA_HOME=/opt/java \ --env DOCKER_HADOOP_HDFS_HOME=/hadoop-current --name distributed-tf-gpu \ --env YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_NETWORK=calico-network \ --worker_docker_image tf-1.13.1-gpu:0.0.1 \ --ps_docker_image tf-1.13.1-cpu:0.0.1 \ --input_path hdfs://${dfs_name_service}/tmp/cifar-10-data \ --checkpoint_path hdfs://${dfs_name_service}/user/hadoop/tf-distributed-checkpoint \ --num_ps 0 \ --ps_resources memory=4G,vcores=2,gpu=0 \ --ps_launch_cmd &amp;quot;python /test/cifar10_estimator/cifar10_main.py --data-dir=hdfs://${dfs_name_service}/tmp/cifar-10-data --job-dir=hdfs://${dfs_name_service}/tmp/cifar-10-jobdir --num-gpus=0&amp;quot; \ --worker_resources memory=4G,vcores=2,gpu=1 --verbose \ --num_workers 1 \ --worker_launch_cmd &amp;quot;python /test/cifar10_estimator/cifar10_main.py --data-dir=hdfs://${dfs_name_service}/tmp/cifar-10-data --job-dir=hdfs://${dfs_name_service}/tmp/cifar-10-jobdir --train-steps=500 --eval-batch-size=16 --train-batch-size=16 --sync --num-gpus=1&amp;quot;  Issues: Issue 1: Fail to start nodemanager after system reboot 2018-09-20 18:54:39,785 ERROR org.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/TonYRuntimeGuide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/TonYRuntimeGuide/</guid>
      <description>TonY Runtime Quick Start Guide Prerequisite Check out the QuickStart
Launch TensorFlow Application: Without Docker You need:
 Build a Python virtual environment with TensorFlow 1.13.1 installed A cluster with Hadoop 2.7 or above. TonY library 0.3.2 or above. Download from here  Building a Python virtual environment with TensorFlow TonY requires a Python virtual environment zip with TensorFlow and any needed Python libraries already installed.
wget https://files.pythonhosted.org/packages/33/bc/fa0b5347139cd9564f0d44ebd2b147ac97c36b2403943dbee8a25fd74012/virtualenv-16.0.0.tar.gz tar xf virtualenv-16.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/WriteDockerfilePT/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/WriteDockerfilePT/</guid>
      <description>Creating Docker Images for Running PyTorch on YARN How to create docker images to run PyTorch on YARN Dockerfile to run PyTorch on YARN needs two parts:
Base libraries which PyTorch depends on
1) OS base image, for example ubuntu:16.04
2) PyTorch dependent libraries and packages. For example python, scipy. For GPU support, you also need cuda, cudnn, etc.
3) PyTorch package.
Libraries to access HDFS
1) JDK
2) Hadoop</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/WriteDockerfileTF/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/WriteDockerfileTF/</guid>
      <description>Creating Docker Images for Running Tensorflow on YARN How to create docker images to run Tensorflow on YARN Dockerfile to run Tensorflow on YARN need two part:
Base libraries which Tensorflow depends on
1) OS base image, for example ubuntu:16.04
2) Tensorflow depended libraries and packages. For example python, scipy. For GPU support, need cuda, cudnn, etc.
3) Tensorflow package.
Libraries to access HDFS
1) JDK
2) Hadoop
Here&amp;rsquo;s an example of a base image (w/o GPU support) to install Tensorflow:</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/Index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/Index/</guid>
      <description> Documentation Choose a version:
 0.2.0
 0.1.0 (Apache Hadoop 3.2.0)
  </description>
    </item>
    
  </channel>
</rss>