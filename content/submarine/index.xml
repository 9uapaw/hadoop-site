<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Hadoop Submarine</title>
    <link>/submarine/</link>
    <description>Recent content on Apache Hadoop Submarine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Apache Software Foundation</copyright>
    <lastBuildDate>Tue, 02 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/submarine/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Release 0.2.0 available</title>
      <link>/submarine/release/0.2.0/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/submarine/release/0.2.0/</guid>
      <description>Apache Hadoop Submarine 0.2.0 is released with following features:
 Linkedin&amp;rsquo;s TonY runtime support in Submarine
 PyTorch enabled in Submarine with both YARN native service runtime (single node) and TonY runtime
 Support uber jar of Submarine to submit the job
 The YAML file to describe a job
 The Notebook support (by Apache Zeppelin Submarine interpreter)
  </description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/BuildFromCode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/BuildFromCode/</guid>
      <description>Build Submarine From Source Code  Run &amp;lsquo;mvn install -DskipTests&amp;rsquo; from Hadoop source top level once.
 Navigate to hadoop-submarine folder and run &amp;lsquo;mvn clean package&amp;rsquo;.
 By default, hadoop-submarine is built based on hadoop 3.1.2 dependencies. Both yarn service runtime and tony runtime are built. You can also add a parameter of &amp;ldquo;-Phadoop-3.2&amp;rdquo; to specify the dependencies to hadoop 3.2.0.
 Hadoop-submarine can support hadoop 2.9.2 and hadoop 2.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/Examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/Examples/</guid>
      <description>Examples Here&amp;rsquo;re some examples about Submarine usage.
Running Distributed CIFAR 10 Tensorflow Job
Running Standalone CIFAR 10 PyTorch Job</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/HowToInstall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/HowToInstall/</guid>
      <description>How to Install Dependencies Submarine project may uses YARN Service (When Submarine YARN service runtime is being used, see QuickStart), Docker container, and GPU (when GPU hardware available and properly configured).
That means as an admin, you may have to properly setup YARN Service related dependencies, including: - YARN Registry DNS
Docker related dependencies, including: - Docker binary with expected versions. - Docker network which allows Docker container can talk to each other across different nodes.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/Index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/Index/</guid>
      <description>Submarine is a project which allows infra engineer / data scientist to run unmodified Tensorflow or PyTorch programs on YARN or Kubernetes.
Goals of Submarine:
 It allows jobs for easy access to data/models in HDFS and other storages.
 Can launch services to serve Tensorflow/MXNet models.
 Support run distributed Tensorflow jobs with simple configs.
 Support run standalone PyTorch jobs with simple configs.
 Support run user-specified Docker images.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/InstallationGuide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/InstallationGuide/</guid>
      <description>Submarine Installation Guide Prerequisites (Please note that all following prerequisites are just an example for you to install. You can always choose to install your own version of kernel, different users, different drivers, etc.).
Operating System The operating system and kernel versions we have tested are as shown in the following table, which is the recommneded minimum required versions.
   Enviroment Verion     Operating System centos-release-7-5.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/InstallationGuideChineseVersion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/InstallationGuideChineseVersion/</guid>
      <description>Submarine 安装说明 Prerequisites 操作系统 我们使用的操作系统版本是 centos-release-7-5.1804.el7.centos.x86_64, 内核版本是 3.10.0-862.el7.x86_64。
   Enviroment Verion     Operating System centos-release-7-5.1804.el7.centos.x86_64   Kernal 3.10.0-862.el7.x86_64    User &amp;amp; Group 如果操作系统中没有这些用户组和用户，必须添加。一部分用户是 hadoop 运行需要，一部分用户是 docker 运行需要。
adduser hdfs adduser mapred adduser yarn addgroup hadoop usermod -aG hdfs,hadoop hdfs usermod -aG mapred,hadoop mapred usermod -aG yarn,hadoop yarn usermod -aG hdfs,hadoop hadoop groupadd docker usermod -aG docker yarn usermod -aG docker hadoop  GCC 版本 gcc --version gcc (GCC) 4.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/QuickStart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/QuickStart/</guid>
      <description>Submarine Quick Start Guide Prerequisite Must:
 Apache Hadoop version newer than 2.7.3  Optional:
 Enable YARN Service Enable GPU on YARN Enable Docker on YARN Build Docker images  
Submarine Configuration After submarine 0.2.0, it supports two runtimes which are YARN service runtime and Linkedin&amp;rsquo;s TonY runtime for YARN. Each runtime can support both Tensorflow and PyTorch framework. But we don&amp;rsquo;t need to worry about the usage because the two runtime implements the same interface.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/RunningDistributedCifar10TFJobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/RunningDistributedCifar10TFJobs/</guid>
      <description>Cifar10 Tensorflow Estimator Example With YARN Service Prepare data for training CIFAR-10 is a common benchmark in machine learning for image recognition. Below example is based on CIFAR-10 dataset.
1) Checkout https://github.com/tensorflow/models/:
git clone https://github.com/tensorflow/models/  2) Go to models/tutorials/image/cifar10_estimator
3) Generate data by using following command: (required Tensorflow installed)
python generate_cifar10_tfrecords.py --data-dir=cifar-10-data  4) Upload data to HDFS
hadoop fs -put cifar-10-data/ /dataset/cifar-10-data  Warning:
Please note that YARN service doesn&amp;rsquo;t allow multiple services with the same name, so please run following command</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/RunningSingleNodeCifar10PTJobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/RunningSingleNodeCifar10PTJobs/</guid>
      <description>Tutorial: Running a standalone Cifar10 PyTorch Estimator Example. Currently, PyTorch integration with Submarine only supports PyTorch in standalone (non-distributed mode). Please also note that HDFS as a data source is not yet supported by PyTorch.
What is CIFAR-10? CIFAR-10 is a common benchmark in machine learning for image recognition. Below example is based on CIFAR-10 dataset.
Warning:
Please note that YARN service doesn&amp;rsquo;t allow multiple services with the same name, so please run following command</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/TestAndTroubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/TestAndTroubleshooting/</guid>
      <description>Test with a tensorflow job Distributed-shell + GPU + cgroup
... \ job run \ --env DOCKER_JAVA_HOME=/opt/java \ --env DOCKER_HADOOP_HDFS_HOME=/hadoop-current --name distributed-tf-gpu \ --env YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_NETWORK=calico-network \ --worker_docker_image tf-1.13.1-gpu:0.0.1 \ --ps_docker_image tf-1.13.1-cpu:0.0.1 \ --input_path hdfs://${dfs_name_service}/tmp/cifar-10-data \ --checkpoint_path hdfs://${dfs_name_service}/user/hadoop/tf-distributed-checkpoint \ --num_ps 0 \ --ps_resources memory=4G,vcores=2,gpu=0 \ --ps_launch_cmd &amp;quot;python /test/cifar10_estimator/cifar10_main.py --data-dir=hdfs://${dfs_name_service}/tmp/cifar-10-data --job-dir=hdfs://${dfs_name_service}/tmp/cifar-10-jobdir --num-gpus=0&amp;quot; \ --worker_resources memory=4G,vcores=2,gpu=1 --verbose \ --num_workers 1 \ --worker_launch_cmd &amp;quot;python /test/cifar10_estimator/cifar10_main.py --data-dir=hdfs://${dfs_name_service}/tmp/cifar-10-data --job-dir=hdfs://${dfs_name_service}/tmp/cifar-10-jobdir --train-steps=500 --eval-batch-size=16 --train-batch-size=16 --sync --num-gpus=1&amp;quot;  Issues: Issue 1: Fail to start nodemanager after system reboot 2018-09-20 18:54:39,785 ERROR org.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/TonYRuntimeGuide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/TonYRuntimeGuide/</guid>
      <description>TonY Runtime Quick Start Guide Prerequisite Check out the QuickStart
Launch TensorFlow Application: Without Docker You need:
 Build a Python virtual environment with TensorFlow 1.13.1 installed A cluster with Hadoop 2.7 or above. TonY library 0.3.2 or above. Download from here  Building a Python virtual environment with TensorFlow TonY requires a Python virtual environment zip with TensorFlow and any needed Python libraries already installed.
wget https://files.pythonhosted.org/packages/33/bc/fa0b5347139cd9564f0d44ebd2b147ac97c36b2403943dbee8a25fd74012/virtualenv-16.0.0.tar.gz tar xf virtualenv-16.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/WriteDockerfilePT/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/WriteDockerfilePT/</guid>
      <description>Creating Docker Images for Running PyTorch on YARN How to create docker images to run PyTorch on YARN Dockerfile to run PyTorch on YARN needs two parts:
Base libraries which PyTorch depends on
1) OS base image, for example ubuntu:16.04
2) PyTorch dependent libraries and packages. For example python, scipy. For GPU support, you also need cuda, cudnn, etc.
3) PyTorch package.
Libraries to access HDFS
1) JDK
2) Hadoop</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/0.2.0/WriteDockerfileTF/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/0.2.0/WriteDockerfileTF/</guid>
      <description>Creating Docker Images for Running Tensorflow on YARN How to create docker images to run Tensorflow on YARN Dockerfile to run Tensorflow on YARN need two part:
Base libraries which Tensorflow depends on
1) OS base image, for example ubuntu:16.04
2) Tensorflow depended libraries and packages. For example python, scipy. For GPU support, need cuda, cudnn, etc.
3) Tensorflow package.
Libraries to access HDFS
1) JDK
2) Hadoop
Here&amp;rsquo;s an example of a base image (w/o GPU support) to install Tensorflow:</description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Documentation</title>
      <link>/submarine/docs/Index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/docs/Index/</guid>
      <description> Documentation Choose a version:
 0.2.0
 0.1.0 (Apache Hadoop 3.2.0)
  </description>
    </item>
    
    <item>
      <title>Apache Hadoop Submarine Releases</title>
      <link>/submarine/downloads/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/downloads/</guid>
      <description>To verify Hadoop Submarine releases using GPG:  Download the release hadoop-submarine-X.Y.Z-src.tar.gz from a mirror site. Download the signature file hadoop-submarine-X.Y.Z-src.tar.gz.asc from Apache. Download the Hadoop KEYS file. gpg &amp;ndash;import KEYS gpg &amp;ndash;verify hadoop-X.Y.Z-src.tar.gz.asc  To perform a quick check using SHA-256:  Download the release hadoop-submarine-X.Y.Z-src.tar.gz from a mirror site. Download the checksum hadoop-submarine-X.Y.Z-src.tar.gz.mds from Apache. shasum -a 256 hadoop-submarine-X.Y.Z-src.tar.gz  All previous releases of Hadoop Submarine are available from the Apache release archive site.</description>
    </item>
    
    <item>
      <title>Hadoop Submarine Eco-system</title>
      <link>/submarine/ecosystem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/ecosystem/</guid>
      <description>Eco-system Submarine installer Hadoop has enabled YARN to support Docker container since 2.x. Hadoop Submarine then uses YARN to schedule and run the distributed deep learning framework in the form of a Docker container.
Since the distributed deep learning framework needs to run in multiple Docker containers and needs to be able to coordinate the various services running in the container, complete the services of model training and model publishing for distributed machine learning.</description>
    </item>
    
    <item>
      <title>Hadoop submarine community activity</title>
      <link>/submarine/activity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/activity/</guid>
      <description>Upcoming Activities Qcon 2019, Beijing  MAY 06–08, 2019
 Apache Hadoop machine learning engine Submarine and ecology.
Submarine is a machine learning platform jointly developed by the Hadoop and Zeppelin communities. It supports Tensorflow, and machine learning frameworks such as Pytorch run in Kubernetes and YARN in a stand-alone or distributed manner.
Now you can use the Submarine-installer to easily install and deploy NVIDIA-Docker, ETCD, Calico and other machines to learn the running environment.</description>
    </item>
    
    <item>
      <title>Questions and Answers</title>
      <link>/submarine/qa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/qa/</guid>
      <description>Regarding to developer/user resources like email list, community calls, how to contribute Please refer to wiki for all these questions.</description>
    </item>
    
    <item>
      <title>Submarine development team</title>
      <link>/submarine/team/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/submarine/team/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>